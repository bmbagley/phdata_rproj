{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import\n",
    "from pyspark.sql import SparkSession, DataFrame\n",
    "import pyspark.sql.functions as F# import year, month, dayofmonth, last_day, date_format, col, trunc\n",
    "from pyspark.sql.types import StructType, StructField, StringType, DateType, IntegerType\n",
    "from pyspark.sql.window import Window\n",
    "import logging\n",
    "import utils\n",
    "# from datetime import datetime, timedelta\n",
    "# import calendar\n",
    "# import pyspark.pandas as ps\n",
    "# from pathlib import Path\n",
    "from dateutil.relativedelta import relativedelta\n",
    "import pathlib\n",
    "\n",
    "from datetime import datetime\n",
    "import calendar\n",
    "\n",
    "valActualsReportDay = 16\n",
    "valOpeningVision = 12\n",
    "valClosingVision = 12\n",
    "valReinvestmentVision = 12\n",
    "valLongRunInflation = 1.025\n",
    "valAnnualizedInflation = 1.0522\n",
    "valAnnualizedInflationBLNLive = 1.01"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Main File, what is already in convertme.py\n",
    "##------------------------------------------\n",
    "sparksesh = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# Load in data using new class\n",
    "pathDataLocation = pathlib.Path(utils.funProjRoot(), \"tests\", \"data\")\n",
    "classDataLoader = utils.FileLoader(sparksesh, pathDataLocation)\n",
    "\n",
    "\n",
    "## Replace Montly Sales aggregation with enrichment, flags and inequalities instead of hard coded rules\n",
    "# NOTE The stored reporting table/data from previous runs can be used to remove already-aggregagted data in previous years\n",
    "def funCreateSalesMonthly(dfSalesMonthly: DataFrame) -> DataFrame:\n",
    "    # dfSalesMonthly =\n",
    "    classSalesEnrich = utils.DateUtils(dfSalesMonthly, \"month\")\n",
    "    # [Potential improvement] Remove previous years of aggregations already stored if CONDITIONS\n",
    "    dfSalesMonthly = classSalesEnrich.add_month_info_columns()\n",
    "    dfSalesMonthly = classSalesEnrich.add_year_info_columns()\n",
    "    dfSalesMonthly = classSalesEnrich.update_leap_year_info()\n",
    "    return dfSalesMonthly, True\n",
    "\n",
    "\n",
    "def funCreateSalesFuture(dfForecast: DataFrame) -> DataFrame:\n",
    "    # Build prediction base dataframe\n",
    "    dfFuture = utils.funForecastUtils(dfForecast)\n",
    "    # Create exploded df by location & prediction_month (typically 120 months)\n",
    "    dfFuture = utils.funSalesFutureBuild(dfFuture)\n",
    "\n",
    "    \n",
    "        # Add yearly date info using utilities\n",
    "    # classFutureEnrich = utils.DateUtils(dfFuture, 'pred_month')\n",
    "    # dfFuture = classFutureEnrich.add_year_info_columns()\n",
    "    # dfFuture = classFutureEnrich.add_month_info_columns()\n",
    "    # dfFuture = classFutureEnrich.update_leap_year_info()\n",
    "\n",
    "    return dfFuture\n",
    "\n",
    "\n",
    "#--- Call functions\n",
    "# dfSalesMonthly, blnLiveForecast = funCreateSalesMonthly(\n",
    "#     classDataLoader.load_file(\"dfMonthlySales.csv\")\n",
    "# )\n",
    "# dfSalesMonthly.show(truncate=True)\n",
    "# root\n",
    "#  |-- loc_num: integer (nullable = true)\n",
    "#  |-- month: date (nullable = true)\n",
    "#  |-- actuals_reported: date (nullable = true)\n",
    "#  |-- open_date: date (nullable = true)\n",
    "#  |-- close_date: string (nullable = true)\n",
    "#  |-- days: double (nullable = true)\n",
    "#  |-- inflation_factor: double (nullable = true)\n",
    "#  |-- inflation_factor_ending: double (nullable = true)\n",
    "#  |-- age: double (nullable = true)\n",
    "#  |-- location_type_code: string (nullable = true)\n",
    "#  |-- concept_code: string (nullable = true)\n",
    "#  |-- sales: double (nullable = true)\n",
    "#  |-- month_integer: integer (nullable = true)\n",
    "#  |-- total_days_in_month: integer (nullable = true)\n",
    "#  |-- year_integer: integer (nullable = true)\n",
    "#  |-- is_leap_year: boolean (nullable = true)\n",
    "#  |-- first_day_of_year: string (nullable = true)\n",
    "\n",
    "\n",
    "# Load in Prediction data and enrich\n",
    "# dfSalesDaysFuture = funCreateSalesFuture(\n",
    "#     classDataLoader.load_file(\"dfSalesDaysFuture.csv\")\n",
    "# )\n",
    "# root\n",
    "#  |-- loc_num: integer (nullable = true)\n",
    "#  |-- location_type_code: string (nullable = true)\n",
    "#  |-- open_date: date (nullable = true)\n",
    "#  |-- close_date: string (nullable = true)\n",
    "#  |-- price_group: integer (nullable = true)\n",
    "#  |-- date_forecast: date (nullable = true)\n",
    "#  |-- months_predict: integer (nullable = true)\n",
    "#  |-- nMonthStart: integer (nullable = false)\n",
    "#  |-- strOpenMonth: string (nullable = true)\n",
    "#  |-- strCloseMonth: string (nullable = true)\n",
    "#  |-- intMonthsBetween: integer (nullable = true)\n",
    "#  |-- month_row: integer (nullable = false)\n",
    "#  |-- pred_month: date (nullable = true)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+----------+----------+-----------+-------------+--------------+-----------+------------+-------------+----------------+---------+----------+\n",
      "|loc_num|location_type_code| open_date|close_date|price_group|date_forecast|months_predict|nMonthStart|strOpenMonth|strCloseMonth|intMonthsBetween|month_row|pred_month|\n",
      "+-------+------------------+----------+----------+-----------+-------------+--------------+-----------+------------+-------------+----------------+---------+----------+\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        0|2025-03-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        1|2025-04-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        2|2025-05-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        3|2025-06-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        4|2025-07-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        5|2025-08-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        6|2025-09-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        7|2025-10-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        8|2025-11-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|        9|2025-12-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       10|2026-01-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       11|2026-02-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       12|2026-03-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       13|2026-04-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       14|2026-05-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       15|2026-06-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       16|2026-07-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       17|2026-08-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       18|2026-09-01|\n",
      "|   1922|        RESTAURANT|2029-02-01|      null|       9139|   2025-03-25|           120|          0|  2029-02-01|   2200-01-01|             120|       19|2026-10-01|\n",
      "+-------+------------------+----------+----------+-----------+-------------+--------------+-----------+------------+-------------+----------------+---------+----------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# dfSalesDaysFuture.printSchema()\n",
    "dfSalesDaysFuture.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------------+------------+-------+----------------+--------------------+----------------------------+------------------+--------------------+--------------------------------+---------------------------+-----------------------------------+--------------------------+\n",
      "|prediction_forecast_months|current_date|seq_row|prediction_month|begin_inflation_rate|begin_inflation_rate_monthly|end_inflation_rate|               slope|intermediate_inflation_rate_init|intermediate_inflation_rate|intermediate_inflation_rate_monthly|incremental_time_inflation|\n",
      "+--------------------------+------------+-------+----------------+--------------------+----------------------------+------------------+--------------------+--------------------------------+---------------------------+-----------------------------------+--------------------------+\n",
      "|                         5|  2025-03-31|      0|      2025-03-01|                 1.0|                         1.0|             1.025|-0.00208333333333...|              1.0187499999999998|         1.0187499999999998|                                1.0|                       1.0|\n",
      "|                         5|  2025-03-31|      1|      2025-04-01|                 1.0|                         1.0|             1.025|-0.00208333333333...|            0.018749999999999822|                        1.0|                                1.0|                       1.0|\n",
      "|                         5|  2025-03-31|      2|      2025-05-01|              1.0522|          1.0042492701806178|             1.025|0.002266666666666676|                         -0.9682|                      1.025|                 1.0020598362698427|        1.0020598362698427|\n",
      "|                         5|  2025-03-31|      3|      2025-06-01|              1.0522|          1.0042492701806178|             1.025|0.002266666666666676|                         -1.9682|                      1.025|                 1.0020598362698427|         1.004123915465144|\n",
      "|                         5|  2025-03-31|      4|      2025-07-01|              1.0522|          1.0042492701806178|             1.025|0.002266666666666676|                         -2.9682|                      1.025|                 1.0020598362698427|        1.0061922463256356|\n",
      "|                         5|  2025-03-31|      5|      2025-08-01|              1.0522|          1.0042492701806178|             1.025|0.002266666666666676|                         -3.9682|                      1.025|                 1.0020598362698427|        1.0082648376090517|\n",
      "+--------------------------+------------+-------+----------------+--------------------+----------------------------+------------------+--------------------+--------------------------------+---------------------------+-----------------------------------+--------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def funBuildIncrementInflation(\n",
    "    spark: SparkSession, prediction_forecast_months: int, annualizedInflation: float\n",
    ") -> DataFrame:\n",
    "    # Define inflation factors and variables\n",
    "    begin_inflation_cutoff_date = \"2025-05-01\"\n",
    "    intermediate_inflation_cutoff_date = \"2026-01-01\"\n",
    "\n",
    "    # Define the schema for the DataFrame\n",
    "    schema = StructType(\n",
    "        [\n",
    "            # StructField(\"current_date\", DateType(), nullable=False),\n",
    "            StructField(\"prediction_forecast_months\", IntegerType(), nullable=False)\n",
    "        ]\n",
    "    )\n",
    "    newdata = [prediction_forecast_months]\n",
    "    df = spark.createDataFrame([newdata], schema)\n",
    "    df = df.withColumn(\"current_date\", F.current_date())\n",
    "\n",
    "    df = funExplodeSeq(df, \"prediction_forecast_months\")\n",
    "    df = (\n",
    "        df.withColumn(\n",
    "            \"prediction_month\",\n",
    "            F.add_months(F.trunc(F.col(\"current_date\"), \"month\"), F.col(\"seq_row\")),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"begin_inflation_rate\",\n",
    "            F.when(\n",
    "                F.col(\"prediction_month\") < begin_inflation_cutoff_date, 1.0\n",
    "            ).otherwise(annualizedInflation),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"begin_inflation_rate_monthly\",\n",
    "            F.when(\n",
    "                F.col(\"seq_row\") > 0, F.col(\"begin_inflation_rate\") ** (1 / 12)\n",
    "            ).otherwise(1.0),\n",
    "        )\n",
    "        .withColumn(\"end_inflation_rate\", F.lit(valLongRunInflation))\n",
    "        .withColumn(\n",
    "            \"slope\", (F.col(\"begin_inflation_rate\") - F.col(\"end_inflation_rate\")) / 12\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"intermediate_inflation_rate_init\",\n",
    "            (\n",
    "                F.col(\"begin_inflation_rate\")\n",
    "                + F.col(\"slope\")\n",
    "                * F.months_between(\n",
    "                    F.col(\"current_date\"), F.lit(intermediate_inflation_cutoff_date)\n",
    "                ).cast(\"integer\")\n",
    "                - F.col(\"seq_row\")\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            \"intermediate_inflation_rate\",\n",
    "            F.least(\n",
    "                F.greatest(\n",
    "                    F.col(\"intermediate_inflation_rate_init\"),\n",
    "                    F.col(\"begin_inflation_rate\"),\n",
    "                ),\n",
    "                F.col(\"end_inflation_rate\"),\n",
    "            ),\n",
    "        )\n",
    "        .withColumn(\n",
    "            'intermediate_inflation_rate_monthly',\n",
    "            F.when(F.col('seq_row') >= 1, F.col('intermediate_inflation_rate')**(1/12)).otherwise(1.0)\n",
    "        )\n",
    "    )\n",
    "\n",
    "    # Add cumulative product of intermediate_inflation_rate_monthly column\n",
    "    window_cumprod = Window.orderBy('prediction_month').rowsBetween(Window.unboundedPreceding,Window.currentRow)\n",
    "    # Add running cumulative product column\n",
    "    df = df.withColumn('incremental_time_inflation', F.product('intermediate_inflation_rate_monthly')\\\n",
    "                .over(window_cumprod))\n",
    "    \n",
    "    return df\n",
    "\n",
    "\n",
    "dfInc = funBuildIncrementInflation(sparksesh, 5, valAnnualizedInflation)\n",
    "dfInc.show(truncate=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def funReinvestmentProjUtils(dfReinvestment: DataFrame) -> DataFrame:\n",
    "#     dfReinvest = (dfReinvestment\n",
    "#     .withColumn(\n",
    "#         'month_shutdown', F.trunc(F.col('shutdown'), 'month')\n",
    "#     ).withColumn(\n",
    "#         'month_reopen', F.trunc(F.col('reopen'), 'month')\n",
    "#     ).withColumn(\n",
    "#         'month_between_openshut', F.months_between(F.col('month_reopen'), F.col('month_shutdown'))\n",
    "#         .cast('integer'))\n",
    "#     )\n",
    "#     return dfReinvest\n",
    "\n",
    "# def funExplodeSeq(df: DataFrame, length_col: str) -> DataFrame:\n",
    "#     dfExplode = (df\n",
    "#         .withColumn(\"startval\", F.lit(0))\n",
    "#         .withColumn(\"seq_list\", F.sequence(start=\"startval\", stop=length_col))\n",
    "#         .withColumn(\"seq_row\", F.explode(\"seq_list\"))\n",
    "#         .drop(\"seq_list\", \"startval\")\n",
    "#     )\n",
    "\n",
    "#     return dfExplode\n",
    "\n",
    "# dfinvest = classDataLoader.load_file(\"dfReinvestmentProjects.csv\")\n",
    "\n",
    "# dfinvest = funReinvestmentProjUtils(dfinvest)\n",
    "\n",
    "# dfinvest = funExplodeSeq(dfinvest, 'month_between_openshut')\n",
    "# dfinvest = dfinvest.withColumn(\n",
    "#     'openshut_month_between', F.add_months(F.col('month_shutdown'), F.col('seq_row'))\n",
    "# ).drop('seq_row')\n",
    "# dfinvest.filter(F.col('month_between_openshut') > 1).show(truncate=True)\n",
    "# # dfinvest.show(truncate=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vscode_pyspark",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
